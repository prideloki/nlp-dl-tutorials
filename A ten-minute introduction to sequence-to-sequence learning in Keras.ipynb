{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trivial Case: len(input) == len(output)\n",
    "\n",
    "https://raw.githubusercontent.com/fchollet/keras/master/examples/addition_rnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/narukawinjidtrengam/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n",
      "Vectorization...\n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 12)             1548      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 12)             0         \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 33s 725us/step - loss: 1.8894 - acc: 0.3219 - val_loss: 1.8123 - val_acc: 0.3419\n",
      "Q 66+251  T 317  \u001b[91m☒\u001b[0m 102 \n",
      "Q 604+26  T 630  \u001b[91m☒\u001b[0m 100 \n",
      "Q 52+636  T 688  \u001b[91m☒\u001b[0m 100 \n",
      "Q 288+53  T 341  \u001b[91m☒\u001b[0m 102 \n",
      "Q 3+873   T 876  \u001b[91m☒\u001b[0m 102 \n",
      "Q 15+78   T 93   \u001b[91m☒\u001b[0m 102 \n",
      "Q 99+40   T 139  \u001b[91m☒\u001b[0m 100 \n",
      "Q 6+883   T 889  \u001b[91m☒\u001b[0m 100 \n",
      "Q 440+101 T 541  \u001b[91m☒\u001b[0m 100 \n",
      "Q 525+212 T 737  \u001b[91m☒\u001b[0m 100 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 550us/step - loss: 1.7479 - acc: 0.3544 - val_loss: 1.6978 - val_acc: 0.3725\n",
      "Q 391+25  T 416  \u001b[91m☒\u001b[0m 333 \n",
      "Q 750+76  T 826  \u001b[91m☒\u001b[0m 706 \n",
      "Q 8+566   T 574  \u001b[91m☒\u001b[0m 166 \n",
      "Q 952+3   T 955  \u001b[91m☒\u001b[0m 116 \n",
      "Q 868+501 T 1369 \u001b[91m☒\u001b[0m 1113\n",
      "Q 864+1   T 865  \u001b[91m☒\u001b[0m 166 \n",
      "Q 202+81  T 283  \u001b[91m☒\u001b[0m 223 \n",
      "Q 19+962  T 981  \u001b[91m☒\u001b[0m 909 \n",
      "Q 384+37  T 421  \u001b[91m☒\u001b[0m 386 \n",
      "Q 702+9   T 711  \u001b[91m☒\u001b[0m 120 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 550us/step - loss: 1.6161 - acc: 0.3943 - val_loss: 1.5415 - val_acc: 0.4182\n",
      "Q 900+300 T 1200 \u001b[91m☒\u001b[0m 1103\n",
      "Q 943+17  T 960  \u001b[91m☒\u001b[0m 904 \n",
      "Q 6+432   T 438  \u001b[91m☒\u001b[0m 444 \n",
      "Q 44+808  T 852  \u001b[91m☒\u001b[0m 894 \n",
      "Q 812+48  T 860  \u001b[91m☒\u001b[0m 884 \n",
      "Q 468+42  T 510  \u001b[91m☒\u001b[0m 594 \n",
      "Q 2+248   T 250  \u001b[91m☒\u001b[0m 227 \n",
      "Q 54+154  T 208  \u001b[91m☒\u001b[0m 554 \n",
      "Q 942+42  T 984  \u001b[91m☒\u001b[0m 904 \n",
      "Q 9+154   T 163  \u001b[91m☒\u001b[0m 154 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 589us/step - loss: 1.4382 - acc: 0.4621 - val_loss: 1.3487 - val_acc: 0.4896: 1.4498 - a - ETA: 2\n",
      "Q 551+48  T 599  \u001b[91m☒\u001b[0m 551 \n",
      "Q 288+366 T 654  \u001b[91m☒\u001b[0m 662 \n",
      "Q 39+938  T 977  \u001b[91m☒\u001b[0m 901 \n",
      "Q 936+33  T 969  \u001b[91m☒\u001b[0m 901 \n",
      "Q 96+137  T 233  \u001b[91m☒\u001b[0m 163 \n",
      "Q 301+43  T 344  \u001b[91m☒\u001b[0m 361 \n",
      "Q 243+94  T 337  \u001b[91m☒\u001b[0m 461 \n",
      "Q 808+973 T 1781 \u001b[91m☒\u001b[0m 1766\n",
      "Q 879+13  T 892  \u001b[91m☒\u001b[0m 881 \n",
      "Q 547+811 T 1358 \u001b[91m☒\u001b[0m 1163\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 566us/step - loss: 1.2653 - acc: 0.5301 - val_loss: 1.2004 - val_acc: 0.5610\n",
      "Q 75+840  T 915  \u001b[91m☒\u001b[0m 811 \n",
      "Q 96+137  T 233  \u001b[91m☒\u001b[0m 104 \n",
      "Q 25+612  T 637  \u001b[91m☒\u001b[0m 631 \n",
      "Q 88+12   T 100  \u001b[91m☒\u001b[0m 80  \n",
      "Q 26+178  T 204  \u001b[91m☒\u001b[0m 281 \n",
      "Q 77+172  T 249  \u001b[91m☒\u001b[0m 284 \n",
      "Q 459+83  T 542  \u001b[91m☒\u001b[0m 504 \n",
      "Q 70+861  T 931  \u001b[91m☒\u001b[0m 839 \n",
      "Q 9+451   T 460  \u001b[91m☒\u001b[0m 451 \n",
      "Q 3+979   T 982  \u001b[91m☒\u001b[0m 970 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 559us/step - loss: 1.1224 - acc: 0.5884 - val_loss: 1.0544 - val_acc: 0.6194\n",
      "Q 942+944 T 1886 \u001b[91m☒\u001b[0m 1812\n",
      "Q 674+260 T 934  \u001b[91m☒\u001b[0m 903 \n",
      "Q 386+487 T 873  \u001b[91m☒\u001b[0m 853 \n",
      "Q 947+29  T 976  \u001b[92m☑\u001b[0m 976 \n",
      "Q 8+873   T 881  \u001b[91m☒\u001b[0m 886 \n",
      "Q 32+617  T 649  \u001b[91m☒\u001b[0m 643 \n",
      "Q 50+42   T 92   \u001b[91m☒\u001b[0m 10  \n",
      "Q 73+635  T 708  \u001b[91m☒\u001b[0m 709 \n",
      "Q 4+679   T 683  \u001b[91m☒\u001b[0m 677 \n",
      "Q 590+43  T 633  \u001b[91m☒\u001b[0m 630 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 572us/step - loss: 1.0032 - acc: 0.6382 - val_loss: 0.9577 - val_acc: 0.6653\n",
      "Q 329+1   T 330  \u001b[91m☒\u001b[0m 339 \n",
      "Q 37+124  T 161  \u001b[91m☒\u001b[0m 162 \n",
      "Q 800+754 T 1554 \u001b[91m☒\u001b[0m 1580\n",
      "Q 438+86  T 524  \u001b[91m☒\u001b[0m 522 \n",
      "Q 52+984  T 1036 \u001b[91m☒\u001b[0m 1030\n",
      "Q 729+701 T 1430 \u001b[91m☒\u001b[0m 1459\n",
      "Q 241+7   T 248  \u001b[91m☒\u001b[0m 247 \n",
      "Q 358+780 T 1138 \u001b[91m☒\u001b[0m 1111\n",
      "Q 559+42  T 601  \u001b[91m☒\u001b[0m 602 \n",
      "Q 79+990  T 1069 \u001b[91m☒\u001b[0m 1072\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 565us/step - loss: 0.9121 - acc: 0.6748 - val_loss: 0.8898 - val_acc: 0.6807\n",
      "Q 614+2   T 616  \u001b[91m☒\u001b[0m 614 \n",
      "Q 78+681  T 759  \u001b[91m☒\u001b[0m 756 \n",
      "Q 74+448  T 522  \u001b[91m☒\u001b[0m 516 \n",
      "Q 35+5    T 40   \u001b[91m☒\u001b[0m 31  \n",
      "Q 839+45  T 884  \u001b[91m☒\u001b[0m 886 \n",
      "Q 542+8   T 550  \u001b[91m☒\u001b[0m 551 \n",
      "Q 74+126  T 200  \u001b[91m☒\u001b[0m 208 \n",
      "Q 8+495   T 503  \u001b[91m☒\u001b[0m 508 \n",
      "Q 723+580 T 1303 \u001b[91m☒\u001b[0m 1200\n",
      "Q 157+42  T 199  \u001b[91m☒\u001b[0m 200 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 556us/step - loss: 0.8408 - acc: 0.7017 - val_loss: 0.8239 - val_acc: 0.7067\n",
      "Q 85+428  T 513  \u001b[91m☒\u001b[0m 511 \n",
      "Q 354+1   T 355  \u001b[92m☑\u001b[0m 355 \n",
      "Q 691+848 T 1539 \u001b[91m☒\u001b[0m 1535\n",
      "Q 495+99  T 594  \u001b[91m☒\u001b[0m 584 \n",
      "Q 29+32   T 61   \u001b[91m☒\u001b[0m 69  \n",
      "Q 6+271   T 277  \u001b[91m☒\u001b[0m 278 \n",
      "Q 580+67  T 647  \u001b[92m☑\u001b[0m 647 \n",
      "Q 209+181 T 390  \u001b[91m☒\u001b[0m 388 \n",
      "Q 987+695 T 1682 \u001b[91m☒\u001b[0m 1655\n",
      "Q 753+18  T 771  \u001b[92m☑\u001b[0m 771 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 547us/step - loss: 0.7741 - acc: 0.7267 - val_loss: 0.7459 - val_acc: 0.7337\n",
      "Q 32+220  T 252  \u001b[91m☒\u001b[0m 255 \n",
      "Q 412+61  T 473  \u001b[91m☒\u001b[0m 475 \n",
      "Q 65+267  T 332  \u001b[91m☒\u001b[0m 335 \n",
      "Q 553+444 T 997  \u001b[91m☒\u001b[0m 900 \n",
      "Q 495+582 T 1077 \u001b[91m☒\u001b[0m 1060\n",
      "Q 996+591 T 1587 \u001b[91m☒\u001b[0m 1561\n",
      "Q 92+19   T 111  \u001b[92m☑\u001b[0m 111 \n",
      "Q 859+321 T 1180 \u001b[92m☑\u001b[0m 1180\n",
      "Q 730+68  T 798  \u001b[91m☒\u001b[0m 791 \n",
      "Q 490+27  T 517  \u001b[91m☒\u001b[0m 518 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 555us/step - loss: 0.6638 - acc: 0.7648 - val_loss: 0.5890 - val_acc: 0.7898\n",
      "Q 559+42  T 601  \u001b[92m☑\u001b[0m 601 \n",
      "Q 972+38  T 1010 \u001b[92m☑\u001b[0m 1010\n",
      "Q 93+0    T 93   \u001b[92m☑\u001b[0m 93  \n",
      "Q 33+431  T 464  \u001b[91m☒\u001b[0m 463 \n",
      "Q 863+464 T 1327 \u001b[91m☒\u001b[0m 1320\n",
      "Q 59+313  T 372  \u001b[91m☒\u001b[0m 380 \n",
      "Q 180+33  T 213  \u001b[91m☒\u001b[0m 204 \n",
      "Q 83+90   T 173  \u001b[91m☒\u001b[0m 174 \n",
      "Q 492+0   T 492  \u001b[91m☒\u001b[0m 493 \n",
      "Q 4+418   T 422  \u001b[92m☑\u001b[0m 422 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 549us/step - loss: 0.4889 - acc: 0.8339 - val_loss: 0.4237 - val_acc: 0.8625\n",
      "Q 563+95  T 658  \u001b[92m☑\u001b[0m 658 \n",
      "Q 127+0   T 127  \u001b[92m☑\u001b[0m 127 \n",
      "Q 991+880 T 1871 \u001b[91m☒\u001b[0m 1842\n",
      "Q 833+59  T 892  \u001b[92m☑\u001b[0m 892 \n",
      "Q 727+7   T 734  \u001b[92m☑\u001b[0m 734 \n",
      "Q 892+407 T 1299 \u001b[91m☒\u001b[0m 1209\n",
      "Q 54+831  T 885  \u001b[92m☑\u001b[0m 885 \n",
      "Q 4+731   T 735  \u001b[92m☑\u001b[0m 735 \n",
      "Q 28+612  T 640  \u001b[91m☒\u001b[0m 639 \n",
      "Q 95+989  T 1084 \u001b[92m☑\u001b[0m 1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 24s 531us/step - loss: 0.3421 - acc: 0.9040 - val_loss: 0.3055 - val_acc: 0.9188\n",
      "Q 686+50  T 736  \u001b[92m☑\u001b[0m 736 \n",
      "Q 2+330   T 332  \u001b[91m☒\u001b[0m 333 \n",
      "Q 95+36   T 131  \u001b[92m☑\u001b[0m 131 \n",
      "Q 402+20  T 422  \u001b[92m☑\u001b[0m 422 \n",
      "Q 45+494  T 539  \u001b[92m☑\u001b[0m 539 \n",
      "Q 241+446 T 687  \u001b[92m☑\u001b[0m 687 \n",
      "Q 39+600  T 639  \u001b[91m☒\u001b[0m 649 \n",
      "Q 36+50   T 86   \u001b[92m☑\u001b[0m 86  \n",
      "Q 663+8   T 671  \u001b[92m☑\u001b[0m 671 \n",
      "Q 581+14  T 595  \u001b[92m☑\u001b[0m 595 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 574us/step - loss: 0.2525 - acc: 0.9392 - val_loss: 0.2531 - val_acc: 0.9251\n",
      "Q 48+33   T 81   \u001b[92m☑\u001b[0m 81  \n",
      "Q 596+102 T 698  \u001b[92m☑\u001b[0m 698 \n",
      "Q 190+81  T 271  \u001b[91m☒\u001b[0m 272 \n",
      "Q 621+67  T 688  \u001b[92m☑\u001b[0m 688 \n",
      "Q 15+115  T 130  \u001b[91m☒\u001b[0m 139 \n",
      "Q 16+183  T 199  \u001b[92m☑\u001b[0m 199 \n",
      "Q 48+733  T 781  \u001b[92m☑\u001b[0m 781 \n",
      "Q 191+576 T 767  \u001b[92m☑\u001b[0m 767 \n",
      "Q 438+86  T 524  \u001b[92m☑\u001b[0m 524 \n",
      "Q 290+100 T 390  \u001b[91m☒\u001b[0m 391 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 558us/step - loss: 0.1932 - acc: 0.9563 - val_loss: 0.1713 - val_acc: 0.9622\n",
      "Q 72+494  T 566  \u001b[92m☑\u001b[0m 566 \n",
      "Q 383+3   T 386  \u001b[92m☑\u001b[0m 386 \n",
      "Q 525+212 T 737  \u001b[92m☑\u001b[0m 737 \n",
      "Q 621+35  T 656  \u001b[92m☑\u001b[0m 656 \n",
      "Q 739+43  T 782  \u001b[92m☑\u001b[0m 782 \n",
      "Q 58+377  T 435  \u001b[92m☑\u001b[0m 435 \n",
      "Q 586+567 T 1153 \u001b[92m☑\u001b[0m 1153\n",
      "Q 472+91  T 563  \u001b[92m☑\u001b[0m 563 \n",
      "Q 301+973 T 1274 \u001b[92m☑\u001b[0m 1274\n",
      "Q 95+153  T 248  \u001b[92m☑\u001b[0m 248 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 24s 539us/step - loss: 0.1435 - acc: 0.9716 - val_loss: 0.1316 - val_acc: 0.9730\n",
      "Q 482+5   T 487  \u001b[92m☑\u001b[0m 487 \n",
      "Q 351+69  T 420  \u001b[92m☑\u001b[0m 420 \n",
      "Q 389+4   T 393  \u001b[92m☑\u001b[0m 393 \n",
      "Q 991+448 T 1439 \u001b[92m☑\u001b[0m 1439\n",
      "Q 791+232 T 1023 \u001b[92m☑\u001b[0m 1023\n",
      "Q 819+30  T 849  \u001b[92m☑\u001b[0m 849 \n",
      "Q 95+397  T 492  \u001b[91m☒\u001b[0m 482 \n",
      "Q 774+415 T 1189 \u001b[92m☑\u001b[0m 1189\n",
      "Q 934+811 T 1745 \u001b[92m☑\u001b[0m 1745\n",
      "Q 898+186 T 1084 \u001b[91m☒\u001b[0m 1073\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 555us/step - loss: 0.1097 - acc: 0.9802 - val_loss: 0.1101 - val_acc: 0.9755\n",
      "Q 582+51  T 633  \u001b[92m☑\u001b[0m 633 \n",
      "Q 929+949 T 1878 \u001b[92m☑\u001b[0m 1878\n",
      "Q 845+6   T 851  \u001b[92m☑\u001b[0m 851 \n",
      "Q 742+41  T 783  \u001b[92m☑\u001b[0m 783 \n",
      "Q 436+620 T 1056 \u001b[92m☑\u001b[0m 1056\n",
      "Q 9+22    T 31   \u001b[91m☒\u001b[0m 32  \n",
      "Q 14+188  T 202  \u001b[92m☑\u001b[0m 202 \n",
      "Q 96+90   T 186  \u001b[92m☑\u001b[0m 186 \n",
      "Q 87+385  T 472  \u001b[92m☑\u001b[0m 472 \n",
      "Q 760+400 T 1160 \u001b[92m☑\u001b[0m 1160\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 24s 541us/step - loss: 0.0924 - acc: 0.9828 - val_loss: 0.0854 - val_acc: 0.9825\n",
      "Q 6+432   T 438  \u001b[92m☑\u001b[0m 438 \n",
      "Q 14+645  T 659  \u001b[92m☑\u001b[0m 659 \n",
      "Q 391+60  T 451  \u001b[92m☑\u001b[0m 451 \n",
      "Q 752+8   T 760  \u001b[92m☑\u001b[0m 760 \n",
      "Q 79+186  T 265  \u001b[92m☑\u001b[0m 265 \n",
      "Q 10+758  T 768  \u001b[92m☑\u001b[0m 768 \n",
      "Q 89+401  T 490  \u001b[92m☑\u001b[0m 490 \n",
      "Q 275+7   T 282  \u001b[92m☑\u001b[0m 282 \n",
      "Q 87+92   T 179  \u001b[91m☒\u001b[0m 189 \n",
      "Q 117+64  T 181  \u001b[92m☑\u001b[0m 181 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 621us/step - loss: 0.0805 - acc: 0.9838 - val_loss: 0.0769 - val_acc: 0.9827\n",
      "Q 36+123  T 159  \u001b[92m☑\u001b[0m 159 \n",
      "Q 849+866 T 1715 \u001b[92m☑\u001b[0m 1715\n",
      "Q 8+916   T 924  \u001b[92m☑\u001b[0m 924 \n",
      "Q 705+23  T 728  \u001b[92m☑\u001b[0m 728 \n",
      "Q 213+61  T 274  \u001b[92m☑\u001b[0m 274 \n",
      "Q 1+579   T 580  \u001b[92m☑\u001b[0m 580 \n",
      "Q 936+33  T 969  \u001b[92m☑\u001b[0m 969 \n",
      "Q 343+329 T 672  \u001b[92m☑\u001b[0m 672 \n",
      "Q 32+218  T 250  \u001b[92m☑\u001b[0m 250 \n",
      "Q 106+33  T 139  \u001b[92m☑\u001b[0m 139 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 27s 594us/step - loss: 0.0624 - acc: 0.9890 - val_loss: 0.0585 - val_acc: 0.9891\n",
      "Q 87+399  T 486  \u001b[92m☑\u001b[0m 486 \n",
      "Q 92+586  T 678  \u001b[92m☑\u001b[0m 678 \n",
      "Q 772+98  T 870  \u001b[92m☑\u001b[0m 870 \n",
      "Q 729+22  T 751  \u001b[92m☑\u001b[0m 751 \n",
      "Q 11+246  T 257  \u001b[92m☑\u001b[0m 257 \n",
      "Q 967+65  T 1032 \u001b[92m☑\u001b[0m 1032\n",
      "Q 46+13   T 59   \u001b[92m☑\u001b[0m 59  \n",
      "Q 178+803 T 981  \u001b[92m☑\u001b[0m 981 \n",
      "Q 5+158   T 163  \u001b[92m☑\u001b[0m 163 \n",
      "Q 80+961  T 1041 \u001b[92m☑\u001b[0m 1041\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 30s 659us/step - loss: 0.0437 - acc: 0.9943 - val_loss: 0.0463 - val_acc: 0.9921\n",
      "Q 111+342 T 453  \u001b[92m☑\u001b[0m 453 \n",
      "Q 59+400  T 459  \u001b[92m☑\u001b[0m 459 \n",
      "Q 44+808  T 852  \u001b[92m☑\u001b[0m 852 \n",
      "Q 58+130  T 188  \u001b[92m☑\u001b[0m 188 \n",
      "Q 467+297 T 764  \u001b[92m☑\u001b[0m 764 \n",
      "Q 950+78  T 1028 \u001b[92m☑\u001b[0m 1028\n",
      "Q 84+993  T 1077 \u001b[92m☑\u001b[0m 1077\n",
      "Q 536+4   T 540  \u001b[92m☑\u001b[0m 540 \n",
      "Q 919+9   T 928  \u001b[92m☑\u001b[0m 928 \n",
      "Q 56+840  T 896  \u001b[92m☑\u001b[0m 896 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 639us/step - loss: 0.0608 - acc: 0.9852 - val_loss: 0.0805 - val_acc: 0.9765\n",
      "Q 98+791  T 889  \u001b[92m☑\u001b[0m 889 \n",
      "Q 659+510 T 1169 \u001b[92m☑\u001b[0m 1169\n",
      "Q 262+73  T 335  \u001b[92m☑\u001b[0m 335 \n",
      "Q 361+77  T 438  \u001b[92m☑\u001b[0m 438 \n",
      "Q 10+167  T 177  \u001b[92m☑\u001b[0m 177 \n",
      "Q 166+303 T 469  \u001b[92m☑\u001b[0m 469 \n",
      "Q 492+740 T 1232 \u001b[92m☑\u001b[0m 1232\n",
      "Q 837+74  T 911  \u001b[92m☑\u001b[0m 911 \n",
      "Q 976+44  T 1020 \u001b[92m☑\u001b[0m 1020\n",
      "Q 991+62  T 1053 \u001b[92m☑\u001b[0m 1053\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 635us/step - loss: 0.0357 - acc: 0.9944 - val_loss: 0.0581 - val_acc: 0.9858\n",
      "Q 85+907  T 992  \u001b[92m☑\u001b[0m 992 \n",
      "Q 955+311 T 1266 \u001b[92m☑\u001b[0m 1266\n",
      "Q 93+714  T 807  \u001b[92m☑\u001b[0m 807 \n",
      "Q 26+321  T 347  \u001b[92m☑\u001b[0m 347 \n",
      "Q 14+16   T 30   \u001b[91m☒\u001b[0m 20  \n",
      "Q 98+301  T 399  \u001b[92m☑\u001b[0m 399 \n",
      "Q 646+727 T 1373 \u001b[92m☑\u001b[0m 1373\n",
      "Q 68+194  T 262  \u001b[92m☑\u001b[0m 262 \n",
      "Q 653+875 T 1528 \u001b[92m☑\u001b[0m 1528\n",
      "Q 463+47  T 510  \u001b[92m☑\u001b[0m 510 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 27s 597us/step - loss: 0.0443 - acc: 0.9898 - val_loss: 0.0376 - val_acc: 0.9923\n",
      "Q 848+47  T 895  \u001b[92m☑\u001b[0m 895 \n",
      "Q 295+7   T 302  \u001b[92m☑\u001b[0m 302 \n",
      "Q 682+68  T 750  \u001b[92m☑\u001b[0m 750 \n",
      "Q 60+507  T 567  \u001b[92m☑\u001b[0m 567 \n",
      "Q 12+113  T 125  \u001b[92m☑\u001b[0m 125 \n",
      "Q 89+973  T 1062 \u001b[92m☑\u001b[0m 1062\n",
      "Q 352+455 T 807  \u001b[92m☑\u001b[0m 807 \n",
      "Q 326+94  T 420  \u001b[92m☑\u001b[0m 420 \n",
      "Q 136+37  T 173  \u001b[92m☑\u001b[0m 173 \n",
      "Q 334+135 T 469  \u001b[92m☑\u001b[0m 469 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 633us/step - loss: 0.0237 - acc: 0.9971 - val_loss: 0.0429 - val_acc: 0.9899\n",
      "Q 796+241 T 1037 \u001b[92m☑\u001b[0m 1037\n",
      "Q 27+39   T 66   \u001b[92m☑\u001b[0m 66  \n",
      "Q 483+63  T 546  \u001b[92m☑\u001b[0m 546 \n",
      "Q 999+6   T 1005 \u001b[92m☑\u001b[0m 1005\n",
      "Q 73+889  T 962  \u001b[92m☑\u001b[0m 962 \n",
      "Q 66+432  T 498  \u001b[92m☑\u001b[0m 498 \n",
      "Q 45+934  T 979  \u001b[92m☑\u001b[0m 979 \n",
      "Q 773+923 T 1696 \u001b[92m☑\u001b[0m 1696\n",
      "Q 684+72  T 756  \u001b[92m☑\u001b[0m 756 \n",
      "Q 253+58  T 311  \u001b[92m☑\u001b[0m 311 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 27s 597us/step - loss: 0.0300 - acc: 0.9940 - val_loss: 0.0450 - val_acc: 0.9873\n",
      "Q 111+130 T 241  \u001b[92m☑\u001b[0m 241 \n",
      "Q 591+10  T 601  \u001b[92m☑\u001b[0m 601 \n",
      "Q 40+547  T 587  \u001b[92m☑\u001b[0m 587 \n",
      "Q 92+674  T 766  \u001b[92m☑\u001b[0m 766 \n",
      "Q 139+566 T 705  \u001b[92m☑\u001b[0m 705 \n",
      "Q 855+77  T 932  \u001b[92m☑\u001b[0m 932 \n",
      "Q 87+665  T 752  \u001b[92m☑\u001b[0m 752 \n",
      "Q 629+846 T 1475 \u001b[92m☑\u001b[0m 1475\n",
      "Q 953+90  T 1043 \u001b[92m☑\u001b[0m 1043\n",
      "Q 939+0   T 939  \u001b[92m☑\u001b[0m 939 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 24s 536us/step - loss: 0.0346 - acc: 0.9919 - val_loss: 0.0294 - val_acc: 0.9926\n",
      "Q 437+861 T 1298 \u001b[92m☑\u001b[0m 1298\n",
      "Q 4+183   T 187  \u001b[92m☑\u001b[0m 187 \n",
      "Q 531+78  T 609  \u001b[92m☑\u001b[0m 609 \n",
      "Q 902+371 T 1273 \u001b[92m☑\u001b[0m 1273\n",
      "Q 675+30  T 705  \u001b[92m☑\u001b[0m 705 \n",
      "Q 85+604  T 689  \u001b[92m☑\u001b[0m 689 \n",
      "Q 609+523 T 1132 \u001b[92m☑\u001b[0m 1132\n",
      "Q 637+64  T 701  \u001b[92m☑\u001b[0m 701 \n",
      "Q 216+22  T 238  \u001b[92m☑\u001b[0m 238 \n",
      "Q 49+914  T 963  \u001b[92m☑\u001b[0m 963 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 585us/step - loss: 0.0199 - acc: 0.9967 - val_loss: 0.0188 - val_acc: 0.9963\n",
      "Q 228+60  T 288  \u001b[92m☑\u001b[0m 288 \n",
      "Q 23+453  T 476  \u001b[92m☑\u001b[0m 476 \n",
      "Q 466+981 T 1447 \u001b[92m☑\u001b[0m 1447\n",
      "Q 88+589  T 677  \u001b[92m☑\u001b[0m 677 \n",
      "Q 25+839  T 864  \u001b[92m☑\u001b[0m 864 \n",
      "Q 99+813  T 912  \u001b[92m☑\u001b[0m 912 \n",
      "Q 138+823 T 961  \u001b[92m☑\u001b[0m 961 \n",
      "Q 72+5    T 77   \u001b[92m☑\u001b[0m 77  \n",
      "Q 429+30  T 459  \u001b[92m☑\u001b[0m 459 \n",
      "Q 14+882  T 896  \u001b[92m☑\u001b[0m 896 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 618us/step - loss: 0.0132 - acc: 0.9984 - val_loss: 0.0582 - val_acc: 0.9830\n",
      "Q 3+399   T 402  \u001b[91m☒\u001b[0m 403 \n",
      "Q 84+77   T 161  \u001b[92m☑\u001b[0m 161 \n",
      "Q 591+10  T 601  \u001b[92m☑\u001b[0m 601 \n",
      "Q 476+53  T 529  \u001b[92m☑\u001b[0m 529 \n",
      "Q 178+362 T 540  \u001b[92m☑\u001b[0m 540 \n",
      "Q 497+557 T 1054 \u001b[91m☒\u001b[0m 1055\n",
      "Q 66+15   T 81   \u001b[92m☑\u001b[0m 81  \n",
      "Q 111+97  T 208  \u001b[92m☑\u001b[0m 208 \n",
      "Q 6+441   T 447  \u001b[92m☑\u001b[0m 447 \n",
      "Q 210+743 T 953  \u001b[92m☑\u001b[0m 953 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 27s 608us/step - loss: 0.0500 - acc: 0.9848 - val_loss: 0.0192 - val_acc: 0.9960\n",
      "Q 306+15  T 321  \u001b[92m☑\u001b[0m 321 \n",
      "Q 942+30  T 972  \u001b[92m☑\u001b[0m 972 \n",
      "Q 39+38   T 77   \u001b[92m☑\u001b[0m 77  \n",
      "Q 542+8   T 550  \u001b[92m☑\u001b[0m 550 \n",
      "Q 0+152   T 152  \u001b[92m☑\u001b[0m 152 \n",
      "Q 20+90   T 110  \u001b[92m☑\u001b[0m 110 \n",
      "Q 44+248  T 292  \u001b[92m☑\u001b[0m 292 \n",
      "Q 40+86   T 126  \u001b[92m☑\u001b[0m 126 \n",
      "Q 27+892  T 919  \u001b[92m☑\u001b[0m 919 \n",
      "Q 10+323  T 333  \u001b[92m☑\u001b[0m 333 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 547us/step - loss: 0.0101 - acc: 0.9993 - val_loss: 0.0144 - val_acc: 0.9973\n",
      "Q 30+56   T 86   \u001b[92m☑\u001b[0m 86  \n",
      "Q 35+568  T 603  \u001b[92m☑\u001b[0m 603 \n",
      "Q 60+859  T 919  \u001b[92m☑\u001b[0m 919 \n",
      "Q 981+11  T 992  \u001b[92m☑\u001b[0m 992 \n",
      "Q 24+232  T 256  \u001b[92m☑\u001b[0m 256 \n",
      "Q 332+2   T 334  \u001b[92m☑\u001b[0m 334 \n",
      "Q 99+557  T 656  \u001b[92m☑\u001b[0m 656 \n",
      "Q 858+332 T 1190 \u001b[92m☑\u001b[0m 1190\n",
      "Q 11+609  T 620  \u001b[92m☑\u001b[0m 620 \n",
      "Q 358+780 T 1138 \u001b[92m☑\u001b[0m 1138\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 550us/step - loss: 0.0083 - acc: 0.9994 - val_loss: 0.0122 - val_acc: 0.9974\n",
      "Q 739+63  T 802  \u001b[92m☑\u001b[0m 802 \n",
      "Q 92+86   T 178  \u001b[92m☑\u001b[0m 178 \n",
      "Q 953+901 T 1854 \u001b[92m☑\u001b[0m 1854\n",
      "Q 781+54  T 835  \u001b[92m☑\u001b[0m 835 \n",
      "Q 42+235  T 277  \u001b[92m☑\u001b[0m 277 \n",
      "Q 533+318 T 851  \u001b[92m☑\u001b[0m 851 \n",
      "Q 60+370  T 430  \u001b[92m☑\u001b[0m 430 \n",
      "Q 46+602  T 648  \u001b[92m☑\u001b[0m 648 \n",
      "Q 13+4    T 17   \u001b[92m☑\u001b[0m 17  \n",
      "Q 29+899  T 928  \u001b[92m☑\u001b[0m 928 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 24s 523us/step - loss: 0.0081 - acc: 0.9992 - val_loss: 0.0239 - val_acc: 0.9937\n",
      "Q 607+478 T 1085 \u001b[92m☑\u001b[0m 1085\n",
      "Q 21+388  T 409  \u001b[92m☑\u001b[0m 409 \n",
      "Q 950+735 T 1685 \u001b[92m☑\u001b[0m 1685\n",
      "Q 514+287 T 801  \u001b[92m☑\u001b[0m 801 \n",
      "Q 87+233  T 320  \u001b[92m☑\u001b[0m 320 \n",
      "Q 48+9    T 57   \u001b[92m☑\u001b[0m 57  \n",
      "Q 81+94   T 175  \u001b[92m☑\u001b[0m 175 \n",
      "Q 783+97  T 880  \u001b[92m☑\u001b[0m 880 \n",
      "Q 133+42  T 175  \u001b[92m☑\u001b[0m 175 \n",
      "Q 425+3   T 428  \u001b[92m☑\u001b[0m 428 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 17s 372us/step - loss: 0.0432 - acc: 0.9868 - val_loss: 0.0244 - val_acc: 0.9932\n",
      "Q 901+30  T 931  \u001b[92m☑\u001b[0m 931 \n",
      "Q 39+361  T 400  \u001b[92m☑\u001b[0m 400 \n",
      "Q 161+5   T 166  \u001b[92m☑\u001b[0m 166 \n",
      "Q 1+749   T 750  \u001b[92m☑\u001b[0m 750 \n",
      "Q 786+843 T 1629 \u001b[92m☑\u001b[0m 1629\n",
      "Q 361+77  T 438  \u001b[92m☑\u001b[0m 438 \n",
      "Q 901+397 T 1298 \u001b[92m☑\u001b[0m 1298\n",
      "Q 389+900 T 1289 \u001b[92m☑\u001b[0m 1289\n",
      "Q 397+70  T 467  \u001b[92m☑\u001b[0m 467 \n",
      "Q 9+316   T 325  \u001b[92m☑\u001b[0m 325 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 16s 363us/step - loss: 0.0082 - acc: 0.9991 - val_loss: 0.0104 - val_acc: 0.9981\n",
      "Q 25+396  T 421  \u001b[92m☑\u001b[0m 421 \n",
      "Q 599+156 T 755  \u001b[92m☑\u001b[0m 755 \n",
      "Q 41+26   T 67   \u001b[92m☑\u001b[0m 67  \n",
      "Q 78+128  T 206  \u001b[92m☑\u001b[0m 206 \n",
      "Q 19+572  T 591  \u001b[92m☑\u001b[0m 591 \n",
      "Q 9+172   T 181  \u001b[92m☑\u001b[0m 181 \n",
      "Q 718+312 T 1030 \u001b[92m☑\u001b[0m 1030\n",
      "Q 547+67  T 614  \u001b[92m☑\u001b[0m 614 \n",
      "Q 54+91   T 145  \u001b[92m☑\u001b[0m 145 \n",
      "Q 47+765  T 812  \u001b[92m☑\u001b[0m 812 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 16s 363us/step - loss: 0.0057 - acc: 0.9997 - val_loss: 0.0095 - val_acc: 0.9978\n",
      "Q 26+785  T 811  \u001b[92m☑\u001b[0m 811 \n",
      "Q 9+917   T 926  \u001b[92m☑\u001b[0m 926 \n",
      "Q 449+21  T 470  \u001b[92m☑\u001b[0m 470 \n",
      "Q 12+894  T 906  \u001b[92m☑\u001b[0m 906 \n",
      "Q 76+578  T 654  \u001b[92m☑\u001b[0m 654 \n",
      "Q 174+13  T 187  \u001b[92m☑\u001b[0m 187 \n",
      "Q 33+987  T 1020 \u001b[92m☑\u001b[0m 1020\n",
      "Q 175+42  T 217  \u001b[92m☑\u001b[0m 217 \n",
      "Q 81+531  T 612  \u001b[92m☑\u001b[0m 612 \n",
      "Q 2+534   T 536  \u001b[92m☑\u001b[0m 536 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 16s 366us/step - loss: 0.0050 - acc: 0.9997 - val_loss: 0.0079 - val_acc: 0.9988\n",
      "Q 2+753   T 755  \u001b[92m☑\u001b[0m 755 \n",
      "Q 27+163  T 190  \u001b[92m☑\u001b[0m 190 \n",
      "Q 807+414 T 1221 \u001b[92m☑\u001b[0m 1221\n",
      "Q 90+719  T 809  \u001b[92m☑\u001b[0m 809 \n",
      "Q 770+899 T 1669 \u001b[92m☑\u001b[0m 1669\n",
      "Q 296+960 T 1256 \u001b[92m☑\u001b[0m 1256\n",
      "Q 725+532 T 1257 \u001b[92m☑\u001b[0m 1257\n",
      "Q 182+147 T 329  \u001b[92m☑\u001b[0m 329 \n",
      "Q 93+780  T 873  \u001b[92m☑\u001b[0m 873 \n",
      "Q 83+65   T 148  \u001b[92m☑\u001b[0m 148 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 588us/step - loss: 0.0470 - acc: 0.9857 - val_loss: 0.0141 - val_acc: 0.9974\n",
      "Q 8+733   T 741  \u001b[92m☑\u001b[0m 741 \n",
      "Q 878+200 T 1078 \u001b[92m☑\u001b[0m 1078\n",
      "Q 163+75  T 238  \u001b[92m☑\u001b[0m 238 \n",
      "Q 253+36  T 289  \u001b[92m☑\u001b[0m 289 \n",
      "Q 3+781   T 784  \u001b[92m☑\u001b[0m 784 \n",
      "Q 892+295 T 1187 \u001b[92m☑\u001b[0m 1187\n",
      "Q 743+569 T 1312 \u001b[92m☑\u001b[0m 1312\n",
      "Q 9+222   T 231  \u001b[92m☑\u001b[0m 231 \n",
      "Q 73+59   T 132  \u001b[92m☑\u001b[0m 132 \n",
      "Q 7+142   T 149  \u001b[92m☑\u001b[0m 149 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 636us/step - loss: 0.0062 - acc: 0.9995 - val_loss: 0.0082 - val_acc: 0.9987\n",
      "Q 63+18   T 81   \u001b[92m☑\u001b[0m 81  \n",
      "Q 863+556 T 1419 \u001b[92m☑\u001b[0m 1419\n",
      "Q 147+899 T 1046 \u001b[92m☑\u001b[0m 1046\n",
      "Q 78+820  T 898  \u001b[92m☑\u001b[0m 898 \n",
      "Q 42+90   T 132  \u001b[92m☑\u001b[0m 132 \n",
      "Q 467+62  T 529  \u001b[92m☑\u001b[0m 529 \n",
      "Q 26+358  T 384  \u001b[92m☑\u001b[0m 384 \n",
      "Q 59+394  T 453  \u001b[92m☑\u001b[0m 453 \n",
      "Q 486+797 T 1283 \u001b[92m☑\u001b[0m 1283\n",
      "Q 839+109 T 948  \u001b[92m☑\u001b[0m 948 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 586us/step - loss: 0.0045 - acc: 0.9997 - val_loss: 0.0090 - val_acc: 0.9979\n",
      "Q 122+914 T 1036 \u001b[92m☑\u001b[0m 1036\n",
      "Q 475+20  T 495  \u001b[92m☑\u001b[0m 495 \n",
      "Q 878+809 T 1687 \u001b[92m☑\u001b[0m 1687\n",
      "Q 825+1   T 826  \u001b[92m☑\u001b[0m 826 \n",
      "Q 702+44  T 746  \u001b[92m☑\u001b[0m 746 \n",
      "Q 725+532 T 1257 \u001b[92m☑\u001b[0m 1257\n",
      "Q 988+25  T 1013 \u001b[92m☑\u001b[0m 1013\n",
      "Q 79+85   T 164  \u001b[92m☑\u001b[0m 164 \n",
      "Q 544+75  T 619  \u001b[92m☑\u001b[0m 619 \n",
      "Q 9+230   T 239  \u001b[92m☑\u001b[0m 239 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 25s 558us/step - loss: 0.0078 - acc: 0.9986 - val_loss: 0.0158 - val_acc: 0.9953\n",
      "Q 228+60  T 288  \u001b[92m☑\u001b[0m 288 \n",
      "Q 3+267   T 270  \u001b[92m☑\u001b[0m 270 \n",
      "Q 437+170 T 607  \u001b[92m☑\u001b[0m 607 \n",
      "Q 402+56  T 458  \u001b[92m☑\u001b[0m 458 \n",
      "Q 295+7   T 302  \u001b[92m☑\u001b[0m 302 \n",
      "Q 759+36  T 795  \u001b[92m☑\u001b[0m 795 \n",
      "Q 827+723 T 1550 \u001b[92m☑\u001b[0m 1550\n",
      "Q 5+212   T 217  \u001b[92m☑\u001b[0m 217 \n",
      "Q 9+788   T 797  \u001b[92m☑\u001b[0m 797 \n",
      "Q 48+766  T 814  \u001b[92m☑\u001b[0m 814 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 572us/step - loss: 0.0435 - acc: 0.9865 - val_loss: 0.0120 - val_acc: 0.9971\n",
      "Q 551+11  T 562  \u001b[92m☑\u001b[0m 562 \n",
      "Q 43+945  T 988  \u001b[92m☑\u001b[0m 988 \n",
      "Q 243+12  T 255  \u001b[92m☑\u001b[0m 255 \n",
      "Q 134+265 T 399  \u001b[92m☑\u001b[0m 399 \n",
      "Q 29+770  T 799  \u001b[92m☑\u001b[0m 799 \n",
      "Q 356+3   T 359  \u001b[92m☑\u001b[0m 359 \n",
      "Q 4+712   T 716  \u001b[92m☑\u001b[0m 716 \n",
      "Q 35+801  T 836  \u001b[92m☑\u001b[0m 836 \n",
      "Q 940+19  T 959  \u001b[92m☑\u001b[0m 959 \n",
      "Q 34+977  T 1011 \u001b[92m☑\u001b[0m 1011\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 586us/step - loss: 0.0043 - acc: 0.9998 - val_loss: 0.0067 - val_acc: 0.9987\n",
      "Q 955+682 T 1637 \u001b[92m☑\u001b[0m 1637\n",
      "Q 0+232   T 232  \u001b[92m☑\u001b[0m 232 \n",
      "Q 11+609  T 620  \u001b[92m☑\u001b[0m 620 \n",
      "Q 60+643  T 703  \u001b[92m☑\u001b[0m 703 \n",
      "Q 86+389  T 475  \u001b[92m☑\u001b[0m 475 \n",
      "Q 270+108 T 378  \u001b[92m☑\u001b[0m 378 \n",
      "Q 480+4   T 484  \u001b[92m☑\u001b[0m 484 \n",
      "Q 0+129   T 129  \u001b[92m☑\u001b[0m 129 \n",
      "Q 47+510  T 557  \u001b[92m☑\u001b[0m 557 \n",
      "Q 308+56  T 364  \u001b[92m☑\u001b[0m 364 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 575us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 0.0057 - val_acc: 0.9990\n",
      "Q 33+212  T 245  \u001b[92m☑\u001b[0m 245 \n",
      "Q 468+42  T 510  \u001b[92m☑\u001b[0m 510 \n",
      "Q 756+374 T 1130 \u001b[92m☑\u001b[0m 1130\n",
      "Q 97+990  T 1087 \u001b[92m☑\u001b[0m 1087\n",
      "Q 3+323   T 326  \u001b[92m☑\u001b[0m 326 \n",
      "Q 15+381  T 396  \u001b[92m☑\u001b[0m 396 \n",
      "Q 407+617 T 1024 \u001b[92m☑\u001b[0m 1024\n",
      "Q 793+99  T 892  \u001b[92m☑\u001b[0m 892 \n",
      "Q 31+119  T 150  \u001b[92m☑\u001b[0m 150 \n",
      "Q 43+75   T 118  \u001b[92m☑\u001b[0m 118 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 30s 660us/step - loss: 0.0029 - acc: 0.9999 - val_loss: 0.0057 - val_acc: 0.9989\n",
      "Q 62+54   T 116  \u001b[92m☑\u001b[0m 116 \n",
      "Q 85+788  T 873  \u001b[92m☑\u001b[0m 873 \n",
      "Q 894+5   T 899  \u001b[92m☑\u001b[0m 899 \n",
      "Q 356+3   T 359  \u001b[92m☑\u001b[0m 359 \n",
      "Q 78+8    T 86   \u001b[92m☑\u001b[0m 86  \n",
      "Q 828+277 T 1105 \u001b[92m☑\u001b[0m 1105\n",
      "Q 5+315   T 320  \u001b[92m☑\u001b[0m 320 \n",
      "Q 273+740 T 1013 \u001b[92m☑\u001b[0m 1013\n",
      "Q 4+956   T 960  \u001b[92m☑\u001b[0m 960 \n",
      "Q 986+161 T 1147 \u001b[92m☑\u001b[0m 1147\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 629us/step - loss: 0.0027 - acc: 0.9998 - val_loss: 0.0056 - val_acc: 0.9986\n",
      "Q 25+839  T 864  \u001b[92m☑\u001b[0m 864 \n",
      "Q 429+385 T 814  \u001b[92m☑\u001b[0m 814 \n",
      "Q 161+29  T 190  \u001b[92m☑\u001b[0m 190 \n",
      "Q 24+722  T 746  \u001b[92m☑\u001b[0m 746 \n",
      "Q 515+292 T 807  \u001b[92m☑\u001b[0m 807 \n",
      "Q 458+564 T 1022 \u001b[92m☑\u001b[0m 1022\n",
      "Q 36+370  T 406  \u001b[92m☑\u001b[0m 406 \n",
      "Q 291+0   T 291  \u001b[92m☑\u001b[0m 291 \n",
      "Q 820+356 T 1176 \u001b[92m☑\u001b[0m 1176\n",
      "Q 96+605  T 701  \u001b[92m☑\u001b[0m 701 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 568us/step - loss: 0.0502 - acc: 0.9852 - val_loss: 0.0219 - val_acc: 0.9936\n",
      "Q 988+65  T 1053 \u001b[92m☑\u001b[0m 1053\n",
      "Q 133+42  T 175  \u001b[92m☑\u001b[0m 175 \n",
      "Q 0+535   T 535  \u001b[92m☑\u001b[0m 535 \n",
      "Q 844+95  T 939  \u001b[92m☑\u001b[0m 939 \n",
      "Q 4+612   T 616  \u001b[92m☑\u001b[0m 616 \n",
      "Q 21+937  T 958  \u001b[92m☑\u001b[0m 958 \n",
      "Q 39+274  T 313  \u001b[92m☑\u001b[0m 313 \n",
      "Q 61+260  T 321  \u001b[92m☑\u001b[0m 321 \n",
      "Q 354+249 T 603  \u001b[92m☑\u001b[0m 603 \n",
      "Q 236+793 T 1029 \u001b[92m☑\u001b[0m 1029\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 548us/step - loss: 0.0057 - acc: 0.9994 - val_loss: 0.0068 - val_acc: 0.9987\n",
      "Q 80+0    T 80   \u001b[92m☑\u001b[0m 80  \n",
      "Q 523+33  T 556  \u001b[92m☑\u001b[0m 556 \n",
      "Q 3+731   T 734  \u001b[92m☑\u001b[0m 734 \n",
      "Q 0+930   T 930  \u001b[92m☑\u001b[0m 930 \n",
      "Q 688+648 T 1336 \u001b[92m☑\u001b[0m 1336\n",
      "Q 7+614   T 621  \u001b[92m☑\u001b[0m 621 \n",
      "Q 294+1   T 295  \u001b[92m☑\u001b[0m 295 \n",
      "Q 38+11   T 49   \u001b[92m☑\u001b[0m 49  \n",
      "Q 753+930 T 1683 \u001b[92m☑\u001b[0m 1683\n",
      "Q 75+140  T 215  \u001b[92m☑\u001b[0m 215 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 560us/step - loss: 0.0027 - acc: 0.9999 - val_loss: 0.0072 - val_acc: 0.9987\n",
      "Q 22+803  T 825  \u001b[92m☑\u001b[0m 825 \n",
      "Q 48+867  T 915  \u001b[92m☑\u001b[0m 915 \n",
      "Q 791+76  T 867  \u001b[92m☑\u001b[0m 867 \n",
      "Q 284+24  T 308  \u001b[92m☑\u001b[0m 308 \n",
      "Q 65+957  T 1022 \u001b[92m☑\u001b[0m 1022\n",
      "Q 965+29  T 994  \u001b[92m☑\u001b[0m 994 \n",
      "Q 744+725 T 1469 \u001b[92m☑\u001b[0m 1469\n",
      "Q 689+30  T 719  \u001b[92m☑\u001b[0m 719 \n",
      "Q 48+309  T 357  \u001b[92m☑\u001b[0m 357 \n",
      "Q 209+206 T 415  \u001b[92m☑\u001b[0m 415 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 573us/step - loss: 0.0026 - acc: 0.9999 - val_loss: 0.0053 - val_acc: 0.9989\n",
      "Q 960+131 T 1091 \u001b[92m☑\u001b[0m 1091\n",
      "Q 8+486   T 494  \u001b[92m☑\u001b[0m 494 \n",
      "Q 233+5   T 238  \u001b[92m☑\u001b[0m 238 \n",
      "Q 4+757   T 761  \u001b[92m☑\u001b[0m 761 \n",
      "Q 86+380  T 466  \u001b[92m☑\u001b[0m 466 \n",
      "Q 54+412  T 466  \u001b[92m☑\u001b[0m 466 \n",
      "Q 52+193  T 245  \u001b[92m☑\u001b[0m 245 \n",
      "Q 477+444 T 921  \u001b[92m☑\u001b[0m 921 \n",
      "Q 41+659  T 700  \u001b[92m☑\u001b[0m 700 \n",
      "Q 107+283 T 390  \u001b[92m☑\u001b[0m 390 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 27s 593us/step - loss: 0.0020 - acc: 0.9999 - val_loss: 0.0045 - val_acc: 0.9992\n",
      "Q 744+184 T 928  \u001b[92m☑\u001b[0m 928 \n",
      "Q 484+491 T 975  \u001b[92m☑\u001b[0m 975 \n",
      "Q 97+942  T 1039 \u001b[92m☑\u001b[0m 1039\n",
      "Q 850+335 T 1185 \u001b[92m☑\u001b[0m 1185\n",
      "Q 942+101 T 1043 \u001b[92m☑\u001b[0m 1043\n",
      "Q 62+54   T 116  \u001b[92m☑\u001b[0m 116 \n",
      "Q 946+352 T 1298 \u001b[92m☑\u001b[0m 1298\n",
      "Q 5+947   T 952  \u001b[92m☑\u001b[0m 952 \n",
      "Q 943+17  T 960  \u001b[92m☑\u001b[0m 960 \n",
      "Q 365+13  T 378  \u001b[92m☑\u001b[0m 378 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 571us/step - loss: 0.0145 - acc: 0.9956 - val_loss: 0.1846 - val_acc: 0.9392\n",
      "Q 9+843   T 852  \u001b[92m☑\u001b[0m 852 \n",
      "Q 955+682 T 1637 \u001b[92m☑\u001b[0m 1637\n",
      "Q 948+30  T 978  \u001b[92m☑\u001b[0m 978 \n",
      "Q 73+635  T 708  \u001b[92m☑\u001b[0m 708 \n",
      "Q 30+130  T 160  \u001b[91m☒\u001b[0m 170 \n",
      "Q 52+485  T 537  \u001b[92m☑\u001b[0m 537 \n",
      "Q 422+4   T 426  \u001b[92m☑\u001b[0m 426 \n",
      "Q 393+979 T 1372 \u001b[92m☑\u001b[0m 1372\n",
      "Q 774+562 T 1336 \u001b[92m☑\u001b[0m 1336\n",
      "Q 492+3   T 495  \u001b[92m☑\u001b[0m 495 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 27s 600us/step - loss: 0.0306 - acc: 0.9904 - val_loss: 0.0071 - val_acc: 0.9986\n",
      "Q 33+61   T 94   \u001b[92m☑\u001b[0m 94  \n",
      "Q 383+21  T 404  \u001b[92m☑\u001b[0m 404 \n",
      "Q 330+620 T 950  \u001b[92m☑\u001b[0m 950 \n",
      "Q 235+717 T 952  \u001b[92m☑\u001b[0m 952 \n",
      "Q 99+931  T 1030 \u001b[92m☑\u001b[0m 1030\n",
      "Q 448+80  T 528  \u001b[92m☑\u001b[0m 528 \n",
      "Q 622+22  T 644  \u001b[92m☑\u001b[0m 644 \n",
      "Q 70+186  T 256  \u001b[92m☑\u001b[0m 256 \n",
      "Q 83+457  T 540  \u001b[92m☑\u001b[0m 540 \n",
      "Q 536+45  T 581  \u001b[92m☑\u001b[0m 581 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 27s 605us/step - loss: 0.0025 - acc: 0.9999 - val_loss: 0.0047 - val_acc: 0.9992\n",
      "Q 67+37   T 104  \u001b[92m☑\u001b[0m 104 \n",
      "Q 981+57  T 1038 \u001b[92m☑\u001b[0m 1038\n",
      "Q 169+5   T 174  \u001b[92m☑\u001b[0m 174 \n",
      "Q 729+895 T 1624 \u001b[92m☑\u001b[0m 1624\n",
      "Q 388+187 T 575  \u001b[92m☑\u001b[0m 575 \n",
      "Q 9+930   T 939  \u001b[92m☑\u001b[0m 939 \n",
      "Q 770+5   T 775  \u001b[92m☑\u001b[0m 775 \n",
      "Q 584+6   T 590  \u001b[92m☑\u001b[0m 590 \n",
      "Q 5+498   T 503  \u001b[92m☑\u001b[0m 503 \n",
      "Q 16+419  T 435  \u001b[92m☑\u001b[0m 435 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 24s 537us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 0.9992\n",
      "Q 76+10   T 86   \u001b[92m☑\u001b[0m 86  \n",
      "Q 90+147  T 237  \u001b[92m☑\u001b[0m 237 \n",
      "Q 44+208  T 252  \u001b[92m☑\u001b[0m 252 \n",
      "Q 8+669   T 677  \u001b[92m☑\u001b[0m 677 \n",
      "Q 197+607 T 804  \u001b[92m☑\u001b[0m 804 \n",
      "Q 825+1   T 826  \u001b[92m☑\u001b[0m 826 \n",
      "Q 306+795 T 1101 \u001b[92m☑\u001b[0m 1101\n",
      "Q 52+328  T 380  \u001b[92m☑\u001b[0m 380 \n",
      "Q 39+563  T 602  \u001b[92m☑\u001b[0m 602 \n",
      "Q 13+113  T 126  \u001b[92m☑\u001b[0m 126 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 576us/step - loss: 0.0017 - acc: 0.9999 - val_loss: 0.0036 - val_acc: 0.9993\n",
      "Q 924+2   T 926  \u001b[92m☑\u001b[0m 926 \n",
      "Q 562+12  T 574  \u001b[92m☑\u001b[0m 574 \n",
      "Q 46+24   T 70   \u001b[92m☑\u001b[0m 70  \n",
      "Q 849+866 T 1715 \u001b[92m☑\u001b[0m 1715\n",
      "Q 239+0   T 239  \u001b[92m☑\u001b[0m 239 \n",
      "Q 11+568  T 579  \u001b[92m☑\u001b[0m 579 \n",
      "Q 5+438   T 443  \u001b[92m☑\u001b[0m 443 \n",
      "Q 49+86   T 135  \u001b[92m☑\u001b[0m 135 \n",
      "Q 708+579 T 1287 \u001b[92m☑\u001b[0m 1287\n",
      "Q 1+78    T 79   \u001b[92m☑\u001b[0m 79  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 640us/step - loss: 0.0015 - acc: 0.9999 - val_loss: 0.0035 - val_acc: 0.9993\n",
      "Q 972+38  T 1010 \u001b[92m☑\u001b[0m 1010\n",
      "Q 425+3   T 428  \u001b[92m☑\u001b[0m 428 \n",
      "Q 4+477   T 481  \u001b[92m☑\u001b[0m 481 \n",
      "Q 14+188  T 202  \u001b[92m☑\u001b[0m 202 \n",
      "Q 145+4   T 149  \u001b[92m☑\u001b[0m 149 \n",
      "Q 807+92  T 899  \u001b[92m☑\u001b[0m 899 \n",
      "Q 891+21  T 912  \u001b[92m☑\u001b[0m 912 \n",
      "Q 136+238 T 374  \u001b[92m☑\u001b[0m 374 \n",
      "Q 39+568  T 607  \u001b[92m☑\u001b[0m 607 \n",
      "Q 660+15  T 675  \u001b[92m☑\u001b[0m 675 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 573us/step - loss: 0.0016 - acc: 0.9999 - val_loss: 0.0050 - val_acc: 0.9987\n",
      "Q 66+822  T 888  \u001b[92m☑\u001b[0m 888 \n",
      "Q 624+985 T 1609 \u001b[92m☑\u001b[0m 1609\n",
      "Q 725+681 T 1406 \u001b[92m☑\u001b[0m 1406\n",
      "Q 676+400 T 1076 \u001b[92m☑\u001b[0m 1076\n",
      "Q 4+841   T 845  \u001b[92m☑\u001b[0m 845 \n",
      "Q 612+568 T 1180 \u001b[92m☑\u001b[0m 1180\n",
      "Q 145+0   T 145  \u001b[92m☑\u001b[0m 145 \n",
      "Q 87+665  T 752  \u001b[92m☑\u001b[0m 752 \n",
      "Q 593+482 T 1075 \u001b[92m☑\u001b[0m 1075\n",
      "Q 43+140  T 183  \u001b[92m☑\u001b[0m 183 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 585us/step - loss: 0.0580 - acc: 0.9819 - val_loss: 0.0911 - val_acc: 0.9682\n",
      "Q 30+130  T 160  \u001b[92m☑\u001b[0m 160 \n",
      "Q 557+895 T 1452 \u001b[92m☑\u001b[0m 1452\n",
      "Q 750+0   T 750  \u001b[92m☑\u001b[0m 750 \n",
      "Q 276+47  T 323  \u001b[92m☑\u001b[0m 323 \n",
      "Q 2+425   T 427  \u001b[92m☑\u001b[0m 427 \n",
      "Q 66+310  T 376  \u001b[92m☑\u001b[0m 376 \n",
      "Q 106+29  T 135  \u001b[92m☑\u001b[0m 135 \n",
      "Q 727+7   T 734  \u001b[92m☑\u001b[0m 734 \n",
      "Q 11+568  T 579  \u001b[92m☑\u001b[0m 579 \n",
      "Q 80+455  T 535  \u001b[92m☑\u001b[0m 535 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 60\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 567us/step - loss: 0.0082 - acc: 0.9980 - val_loss: 0.0051 - val_acc: 0.9990\n",
      "Q 96+441  T 537  \u001b[92m☑\u001b[0m 537 \n",
      "Q 133+42  T 175  \u001b[92m☑\u001b[0m 175 \n",
      "Q 993+7   T 1000 \u001b[92m☑\u001b[0m 1000\n",
      "Q 495+99  T 594  \u001b[92m☑\u001b[0m 594 \n",
      "Q 470+644 T 1114 \u001b[92m☑\u001b[0m 1114\n",
      "Q 127+606 T 733  \u001b[92m☑\u001b[0m 733 \n",
      "Q 967+65  T 1032 \u001b[92m☑\u001b[0m 1032\n",
      "Q 95+974  T 1069 \u001b[92m☑\u001b[0m 1069\n",
      "Q 622+557 T 1179 \u001b[92m☑\u001b[0m 1179\n",
      "Q 368+70  T 438  \u001b[92m☑\u001b[0m 438 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 61\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 548us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Q 710+43  T 753  \u001b[92m☑\u001b[0m 753 \n",
      "Q 929+29  T 958  \u001b[92m☑\u001b[0m 958 \n",
      "Q 23+208  T 231  \u001b[92m☑\u001b[0m 231 \n",
      "Q 41+132  T 173  \u001b[92m☑\u001b[0m 173 \n",
      "Q 7+878   T 885  \u001b[92m☑\u001b[0m 885 \n",
      "Q 40+394  T 434  \u001b[92m☑\u001b[0m 434 \n",
      "Q 742+475 T 1217 \u001b[92m☑\u001b[0m 1217\n",
      "Q 28+197  T 225  \u001b[92m☑\u001b[0m 225 \n",
      "Q 519+50  T 569  \u001b[92m☑\u001b[0m 569 \n",
      "Q 71+47   T 118  \u001b[92m☑\u001b[0m 118 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 62\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 569us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9992\n",
      "Q 20+438  T 458  \u001b[92m☑\u001b[0m 458 \n",
      "Q 3+948   T 951  \u001b[92m☑\u001b[0m 951 \n",
      "Q 425+23  T 448  \u001b[92m☑\u001b[0m 448 \n",
      "Q 489+53  T 542  \u001b[92m☑\u001b[0m 542 \n",
      "Q 865+56  T 921  \u001b[92m☑\u001b[0m 921 \n",
      "Q 771+358 T 1129 \u001b[92m☑\u001b[0m 1129\n",
      "Q 54+831  T 885  \u001b[92m☑\u001b[0m 885 \n",
      "Q 5+197   T 202  \u001b[92m☑\u001b[0m 202 \n",
      "Q 8+733   T 741  \u001b[92m☑\u001b[0m 741 \n",
      "Q 585+65  T 650  \u001b[92m☑\u001b[0m 650 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 63\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 566us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9994\n",
      "Q 32+2    T 34   \u001b[92m☑\u001b[0m 34  \n",
      "Q 806+75  T 881  \u001b[92m☑\u001b[0m 881 \n",
      "Q 681+30  T 711  \u001b[92m☑\u001b[0m 711 \n",
      "Q 39+389  T 428  \u001b[92m☑\u001b[0m 428 \n",
      "Q 7+734   T 741  \u001b[92m☑\u001b[0m 741 \n",
      "Q 824+760 T 1584 \u001b[92m☑\u001b[0m 1584\n",
      "Q 76+578  T 654  \u001b[92m☑\u001b[0m 654 \n",
      "Q 30+181  T 211  \u001b[92m☑\u001b[0m 211 \n",
      "Q 5+832   T 837  \u001b[92m☑\u001b[0m 837 \n",
      "Q 25+305  T 330  \u001b[92m☑\u001b[0m 330 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 64\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "44416/45000 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9998"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-655bbe31384b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m               validation_data=(x_val, y_val))\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;31m# Select 10 samples from the validation set at random so we can visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''An implementation of sequence to sequence learning for performing addition\n",
    "\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "\n",
    "Input may optionally be inverted, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "\n",
    "Two digits inverted:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "\n",
    "Three digits inverted:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "\n",
    "Four digits inverted:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "\n",
    "Five digits inverted:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "\n",
    "\n",
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "INVERT = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if INVERT:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for iteration in range(1, 200):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q[::-1] if INVERT else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Case: canonical sequence-to-sequence\n",
    "\n",
    "simaple machine translation\n",
    "\n",
    "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
    "\n",
    "https://github.com/fchollet/keras/blob/master/examples/lstm_seq2seq.py\n",
    "\n",
    "\n",
    "## References\n",
    "- Sequence to Sequence Learning with Neural Networks\n",
    "    https://arxiv.org/abs/1409.3215\n",
    "- Learning Phrase Representations using\n",
    "    RNN Encoder-Decoder for Statistical Machine Translation\n",
    "    https://arxiv.org/abs/1406.1078"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "latent_dim = 256\n",
    "num_samples = 10000\n",
    "\n",
    "data_path = 'fra-eng/fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 71\n",
      "Number of unique output tokens: 93\n",
      "Max sequence length for inputs: 16\n",
      "Max sequence length for outputs: 59\n"
     ]
    }
   ],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "lines = open(data_path).read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)]\n",
    ")\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)]\n",
    ")\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        # decoder_target_data ahead of decoder_input by 1 step\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t-1, target_token_index[char]] = 1\n",
    "            \n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                    initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 58s 7ms/step - loss: 0.9307 - val_loss: 0.9735\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.7378 - val_loss: 0.8054\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 56s 7ms/step - loss: 0.6252 - val_loss: 0.7103\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 56s 7ms/step - loss: 0.5659 - val_loss: 0.6632\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 59s 7ms/step - loss: 0.5231 - val_loss: 0.6256\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 57s 7ms/step - loss: 0.4900 - val_loss: 0.5978\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 56s 7ms/step - loss: 0.4629 - val_loss: 0.5790\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 57s 7ms/step - loss: 0.4406 - val_loss: 0.5598\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 57s 7ms/step - loss: 0.4205 - val_loss: 0.5438\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 57s 7ms/step - loss: 0.4024 - val_loss: 0.5323\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 57s 7ms/step - loss: 0.3860 - val_loss: 0.5225\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 58s 7ms/step - loss: 0.3711 - val_loss: 0.5116\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 58s 7ms/step - loss: 0.3571 - val_loss: 0.5018\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 58s 7ms/step - loss: 0.3442 - val_loss: 0.4949\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.3321 - val_loss: 0.4916\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.3207 - val_loss: 0.4881\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 60s 7ms/step - loss: 0.3096 - val_loss: 0.4869\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.2995 - val_loss: 0.4807\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.2896 - val_loss: 0.4810\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.2799 - val_loss: 0.4826\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.2713 - val_loss: 0.4812\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.2624 - val_loss: 0.4806\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.2545 - val_loss: 0.4812\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 66s 8ms/step - loss: 0.2467 - val_loss: 0.4810\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 70s 9ms/step - loss: 0.2393 - val_loss: 0.4808\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 72s 9ms/step - loss: 0.2321 - val_loss: 0.4825\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 68s 8ms/step - loss: 0.2251 - val_loss: 0.4837\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.2184 - val_loss: 0.4947\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 67s 8ms/step - loss: 0.2120 - val_loss: 0.5020\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 67s 8ms/step - loss: 0.2060 - val_loss: 0.4934\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.2000 - val_loss: 0.4985\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 60s 7ms/step - loss: 0.1942 - val_loss: 0.5064\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.1888 - val_loss: 0.5052\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.1833 - val_loss: 0.5147\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.1784 - val_loss: 0.5138\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.1738 - val_loss: 0.5159\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.1691 - val_loss: 0.5236\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.1651 - val_loss: 0.5264\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1605 - val_loss: 0.5355\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.1563 - val_loss: 0.5356\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1525 - val_loss: 0.5416\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 66s 8ms/step - loss: 0.1487 - val_loss: 0.5516\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 66s 8ms/step - loss: 0.1454 - val_loss: 0.5535\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.1417 - val_loss: 0.5590\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.1383 - val_loss: 0.5636\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.1351 - val_loss: 0.5672\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.1322 - val_loss: 0.5708\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.1292 - val_loss: 0.5759\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.1263 - val_loss: 0.5816\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.1237 - val_loss: 0.5866\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.1209 - val_loss: 0.5905\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.1183 - val_loss: 0.5962\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.1161 - val_loss: 0.6007\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1134 - val_loss: 0.6016\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.1113 - val_loss: 0.6098\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.1091 - val_loss: 0.6144\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 66s 8ms/step - loss: 0.1068 - val_loss: 0.6216\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.1047 - val_loss: 0.6257\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.1028 - val_loss: 0.6312\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.1009 - val_loss: 0.6306\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.0992 - val_loss: 0.6353\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.0975 - val_loss: 0.6389\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 69s 9ms/step - loss: 0.0954 - val_loss: 0.6400\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 66s 8ms/step - loss: 0.0935 - val_loss: 0.6499\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.0922 - val_loss: 0.6551\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 72s 9ms/step - loss: 0.0907 - val_loss: 0.6517\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 68s 9ms/step - loss: 0.0891 - val_loss: 0.6604\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0873 - val_loss: 0.6654\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 67s 8ms/step - loss: 0.0859 - val_loss: 0.6652\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 81s 10ms/step - loss: 0.0843 - val_loss: 0.6678\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 74s 9ms/step - loss: 0.0830 - val_loss: 0.6790\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 67s 8ms/step - loss: 0.0815 - val_loss: 0.6811\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 60s 7ms/step - loss: 0.0801 - val_loss: 0.6856\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 59s 7ms/step - loss: 0.0792 - val_loss: 0.6786\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.0778 - val_loss: 0.6914\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 66s 8ms/step - loss: 0.0763 - val_loss: 0.6938\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 66s 8ms/step - loss: 0.0754 - val_loss: 0.7020\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 67s 8ms/step - loss: 0.0742 - val_loss: 0.7052\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.0730 - val_loss: 0.7028\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0720 - val_loss: 0.7109\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 60s 7ms/step - loss: 0.0703 - val_loss: 0.7173\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.0697 - val_loss: 0.7137\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.0685 - val_loss: 0.7240\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.0676 - val_loss: 0.7218\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 66s 8ms/step - loss: 0.0669 - val_loss: 0.7304\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.0659 - val_loss: 0.7291\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0647 - val_loss: 0.7301\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0639 - val_loss: 0.7387\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.0628 - val_loss: 0.7387\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0620 - val_loss: 0.7466\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.0610 - val_loss: 0.7459\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0605 - val_loss: 0.7433\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.0594 - val_loss: 0.7539\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 71s 9ms/step - loss: 0.0586 - val_loss: 0.7449\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 66s 8ms/step - loss: 0.0576 - val_loss: 0.7572\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 69s 9ms/step - loss: 0.0570 - val_loss: 0.7614\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0561 - val_loss: 0.7628\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.0554 - val_loss: 0.7664\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 60s 7ms/step - loss: 0.0550 - val_loss: 0.7696\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.0540 - val_loss: 0.7750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/narukawinjidtrengam/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:2344: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_3/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_3/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "         batch_size=batch_size,\n",
    "         epochs=epochs,\n",
    "         validation_split=0.2)\n",
    "\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference mode (sampling)\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items()\n",
    ")\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Va !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Courez !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Courez !\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Ça aorre Tom.\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Au feu !\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: À l'aide !\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Saute.\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Stop !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Stop !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Stop !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attendez !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attendez !\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Je les vois.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: J'essaye.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: J'ai gagné !\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: J'ai gagné !\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: Oh non !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attaque !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attaque !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Tchin-tchin !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Tchin-tchin !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Tchin-tchin !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Tchin-tchin !\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Lève-toi.\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Compris de nous !\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Compris de nous !\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Pigé ?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Pigé ?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Pigé ?\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Montez.\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Montez.\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Serrez-moi dans vos bras !\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Serrez-moi dans vos bras !\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je suis tombée.\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je suis tombée.\n",
      "\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: Je le sais.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je suis partie.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je suis partie.\n",
      "\n",
      "-\n",
      "Input sentence: I lost.\n",
      "Decoded sentence: J'ai perdu.\n",
      "\n",
      "-\n",
      "Input sentence: I'm 19.\n",
      "Decoded sentence: Je suis chanceux.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je suis voyant.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je suis voyant.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Écoutez !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Vrai ?\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Vrai ?\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Vrai ?\n",
      "\n",
      "-\n",
      "Input sentence: Thanks.\n",
      "Decoded sentence: Merci !\n",
      "\n",
      "-\n",
      "Input sentence: We try.\n",
      "Decoded sentence: On essaye.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous avons gagné.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous avons gagné.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous avons gagné.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous avons gagné.\n",
      "\n",
      "-\n",
      "Input sentence: Ask Tom.\n",
      "Decoded sentence: Demande à Tom.\n",
      "\n",
      "-\n",
      "Input sentence: Awesome!\n",
      "Decoded sentence: Fantastique !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Soyez calmes !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Soyez calmes !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Soyez calmes !\n",
      "\n",
      "-\n",
      "Input sentence: Be cool.\n",
      "Decoded sentence: Sois détendu !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez juste !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez juste !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez juste !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez juste !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez juste !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez juste !\n",
      "\n",
      "-\n",
      "Input sentence: Be kind.\n",
      "Decoded sentence: Sois gentil.\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Sois gentil !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Sois gentil !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Sois gentil !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Sois gentil !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Sois gentil !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Sois gentil !\n",
      "\n",
      "-\n",
      "Input sentence: Beat it.\n",
      "Decoded sentence: Dégage !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Appellez-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Appellez-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: Appelle-nous !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: Appelle-nous !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entre !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entre !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entre !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entre !\n",
      "\n",
      "-\n",
      "Input sentence: Come on!\n",
      "Decoded sentence: Aidez !\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Viens !\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Viens !\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Viens !\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Laissez-le tomber !\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Laissez-le tomber !\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Laissez-le tomber !\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Laissez-le tomber !\n",
      "\n",
      "-\n",
      "Input sentence: Get out!\n",
      "Decoded sentence: Sortez !\n",
      "\n",
      "-\n",
      "Input sentence: Get out!\n",
      "Decoded sentence: Sortez !\n",
      "\n",
      "-\n",
      "Input sentence: Get out!\n",
      "Decoded sentence: Sortez !\n",
      "\n",
      "-\n",
      "Input sentence: Get out.\n",
      "Decoded sentence: Sors.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training test)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decoder_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
